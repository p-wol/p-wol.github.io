{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fbc7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re    # regular expressions\n",
    "import string    # string manipulation\n",
    "from collections import Counter\n",
    "import copy\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37131f",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes classification on text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a75d1",
   "metadata": {},
   "source": [
    "The goal of this exercise is to use a naive Bayes model to classify text files. Each text file is given a category (\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"), and the goal is to infer this category from an analysis of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e9372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"bbc\"\n",
    "path_stopwords = \"bbc/stopwords-en.txt\"\n",
    "list_classes = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
    "n_classes = len(list_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcf821",
   "metadata": {},
   "source": [
    "**Preliminary question**\n",
    "\n",
    "Open some of the text files and take a look at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6fe4d",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4223e5",
   "metadata": {},
   "source": [
    "First, the data must be loaded. One must load the \"stop-words\", that are the words that are commonly used in English, and are not believed to contain any crucial information about the theme of the text. Then, the files must be loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4213c0",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Store the content of the stopwords file into a set of strings. Add to it the empty string \"\".\n",
    "\n",
    "One can use the string method `rstrip` to remove the trailing blank characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92177f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5379eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5266c6",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Write a function loading the dataset into a dictionary `dct_data`:\n",
    " * whose keys are the classes names;\n",
    " * whose values are the lists of the contents of the text files.\n",
    "For instance, `dct_data[\"business\"]` returns a list of strings, where each string is the content of a file (in the folder \"business\").\n",
    "\n",
    "One can use the function `os.path.join` to build paths to files, `os.listdir` to list all the files contained in a directory and the file method `read` to gather the entire content of a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2ad929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac263e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2ce002c",
   "metadata": {},
   "source": [
    "## Preprocess the data\n",
    "\n",
    "We want to use perform Multinomial Naive Bayes on this dataset. To use it, we have first to precprocess the data (clean the text, prepare the data for the naive Bayes method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd029f",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Write a function to remove the punctuation from a string, a function to transform all characters of a string into lower-case characters, and a function that transforms a string into the list of words it contains.\n",
    "\n",
    "One can use the string method `translate`, the static method `str.maketrans`, the in-built string `string.punctuation`, and `re.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5943ea9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e23b9d4c",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Process the texts to transform them into lists of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31eb4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f788c55e",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Create the set of all the different words present in the texts, excuding the stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e81d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2eb2a7b",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "Create the array of features of the dataset. This array must be of size n * p, where n is the number of texts, and p is the number of different words in the dataset. Each row i must contain the number of occurrences of each word. For example, the coefficient at (i, j) contains the number of occurrences of the word n° j in the text n° i. Create also the array of targets: this should be an array of size n, where the coefficient n° i contains a number representing the class of the text n° i.\n",
    "\n",
    "Note: one should give one number to each word of the set and to each class.\n",
    "\n",
    "The object `collections.Counter` can be very useful in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2795a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f6ecba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74a4cc17",
   "metadata": {},
   "source": [
    "## By-hand multinomial naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08bf26",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "\n",
    "Split the dataset into a training set and a test set (we do not need a validation set since we do not perform model selection).\n",
    "\n",
    "The first step of naive Bayes is to find the distribution that fits the best to the training data. Given a class $c$, with the multinomial distribution $\\mathcal{M}(\\theta_1^c, \\theta_2^c, \\cdots, \\theta_p^c, p)$, we want to find the parameters $\\hat{\\theta}_j^c$ maximizing the likehood of the training data. We have:\n",
    "$$\n",
    "\\hat{\\theta}_j^c = \\frac{n_j^c}{\\sum_{k = 1}^p n_k^c} ,\n",
    "$$\n",
    "where $n_j^c$ is the number of occurrences of the word n° j in the texts with label c.\n",
    "\n",
    "We will not use this formula, but a regularized version of it:\n",
    "$$\n",
    "\\hat{\\theta}_j^c = \\frac{n_j^c + \\alpha}{\\sum_{k = 1}^p n_k^c + \\alpha p} ,\n",
    "$$\n",
    "where $\\alpha > 0$ to avoid a zero denominator. We can set $\\alpha = 1$.\n",
    "\n",
    "Compute the $\\hat{\\theta}_j^c$ for each class c and each word j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2459e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bc793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7a083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e586b7",
   "metadata": {},
   "source": [
    "**Question 8**\n",
    "\n",
    "Predict the classes of the test dataset. From a Bayesian point of view, for each data point, the chosen class should maximize the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85929bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d86d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a058d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2fd4f63",
   "metadata": {},
   "source": [
    "## Multinomial naive Bayes with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33266aff",
   "metadata": {},
   "source": [
    "**Question 9**\n",
    "\n",
    "Split the dataset into a training set and a test set (we do not need a validation set since we do not perform model selection).\n",
    "\n",
    "Use `sklearn.naive_bayes.MultinomialNB`: train it on the train set and compute the score on the test set. What do the score represent? Comment the efficiency of naive Bayes in this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2c1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a058024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ad7d9ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c11bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5abf60d",
   "metadata": {},
   "source": [
    "# Gaussian naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c66136",
   "metadata": {},
   "source": [
    "We will perform Gaussian naive Bayes on the \"iris\" dataset of sklearn. There are 4 features and 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92776b96",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405616c9",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Load the \"Iris\" dataset. and split it into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bfe39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7605c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0895087d",
   "metadata": {},
   "source": [
    "## By-hand Gaussian naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c4183",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db50bd",
   "metadata": {},
   "source": [
    "For each class, for each feature, compute the optimal parameters of the Gaussian (used to model the current feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6a926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "feea8b1f",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Compute the prior over the classes based on the population inside each class.\n",
    "\n",
    "Predict the class of the data points belonging to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fae53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eda054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f5a63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bc865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62dbbba6",
   "metadata": {},
   "source": [
    "## Gaussian naive Bayes with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052308ce",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Perform the Gaussian naive Bayes with sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f714e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36279024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32fd0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d3dd0c1",
   "metadata": {},
   "source": [
    "**Question 5**\n",
    "\n",
    "Compare with the knn classifier with $k = 5$ neighbors by using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f492ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729fb1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35878236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c70b60cc",
   "metadata": {},
   "source": [
    "# Learning from multimodal features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e5e98",
   "metadata": {},
   "source": [
    "We will process a dataset of predictive maintenance. The goal is to predict the failure type on a machine in function of physical measures and the type of machine. So, we are in a classification setup with multimodal features (categorical features and numerical features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85443e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_000, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>UDI</th><th>Product ID</th><th>Type</th><th>Air temperature [K]</th><th>Process temperature [K]</th><th>Rotational speed [rpm]</th><th>Torque [Nm]</th><th>Tool wear [min]</th><th>Target</th><th>Failure Type</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>1</td><td>&quot;M14860&quot;</td><td>&quot;M&quot;</td><td>298.1</td><td>308.6</td><td>1551</td><td>42.8</td><td>0</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>2</td><td>&quot;L47181&quot;</td><td>&quot;L&quot;</td><td>298.2</td><td>308.7</td><td>1408</td><td>46.3</td><td>3</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>3</td><td>&quot;L47182&quot;</td><td>&quot;L&quot;</td><td>298.1</td><td>308.5</td><td>1498</td><td>49.4</td><td>5</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>4</td><td>&quot;L47183&quot;</td><td>&quot;L&quot;</td><td>298.2</td><td>308.6</td><td>1433</td><td>39.5</td><td>7</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>5</td><td>&quot;L47184&quot;</td><td>&quot;L&quot;</td><td>298.2</td><td>308.7</td><td>1408</td><td>40.0</td><td>9</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9996</td><td>&quot;M24855&quot;</td><td>&quot;M&quot;</td><td>298.8</td><td>308.4</td><td>1604</td><td>29.5</td><td>14</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>9997</td><td>&quot;H39410&quot;</td><td>&quot;H&quot;</td><td>298.9</td><td>308.4</td><td>1632</td><td>31.8</td><td>17</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>9998</td><td>&quot;M24857&quot;</td><td>&quot;M&quot;</td><td>299.0</td><td>308.6</td><td>1645</td><td>33.4</td><td>22</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>9999</td><td>&quot;H39412&quot;</td><td>&quot;H&quot;</td><td>299.0</td><td>308.7</td><td>1408</td><td>48.5</td><td>25</td><td>0</td><td>&quot;No Failure&quot;</td></tr><tr><td>10000</td><td>&quot;M24859&quot;</td><td>&quot;M&quot;</td><td>299.0</td><td>308.7</td><td>1500</td><td>40.2</td><td>30</td><td>0</td><td>&quot;No Failure&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_000, 10)\n",
       "┌───────┬────────────┬──────┬──────────────┬───┬─────────────┬──────────────┬────────┬─────────────┐\n",
       "│ UDI   ┆ Product ID ┆ Type ┆ Air          ┆ … ┆ Torque [Nm] ┆ Tool wear    ┆ Target ┆ Failure     │\n",
       "│ ---   ┆ ---        ┆ ---  ┆ temperature  ┆   ┆ ---         ┆ [min]        ┆ ---    ┆ Type        │\n",
       "│ i64   ┆ str        ┆ str  ┆ [K]          ┆   ┆ f64         ┆ ---          ┆ i64    ┆ ---         │\n",
       "│       ┆            ┆      ┆ ---          ┆   ┆             ┆ i64          ┆        ┆ str         │\n",
       "│       ┆            ┆      ┆ f64          ┆   ┆             ┆              ┆        ┆             │\n",
       "╞═══════╪════════════╪══════╪══════════════╪═══╪═════════════╪══════════════╪════════╪═════════════╡\n",
       "│ 1     ┆ M14860     ┆ M    ┆ 298.1        ┆ … ┆ 42.8        ┆ 0            ┆ 0      ┆ No Failure  │\n",
       "│ 2     ┆ L47181     ┆ L    ┆ 298.2        ┆ … ┆ 46.3        ┆ 3            ┆ 0      ┆ No Failure  │\n",
       "│ 3     ┆ L47182     ┆ L    ┆ 298.1        ┆ … ┆ 49.4        ┆ 5            ┆ 0      ┆ No Failure  │\n",
       "│ 4     ┆ L47183     ┆ L    ┆ 298.2        ┆ … ┆ 39.5        ┆ 7            ┆ 0      ┆ No Failure  │\n",
       "│ 5     ┆ L47184     ┆ L    ┆ 298.2        ┆ … ┆ 40.0        ┆ 9            ┆ 0      ┆ No Failure  │\n",
       "│ …     ┆ …          ┆ …    ┆ …            ┆ … ┆ …           ┆ …            ┆ …      ┆ …           │\n",
       "│ 9996  ┆ M24855     ┆ M    ┆ 298.8        ┆ … ┆ 29.5        ┆ 14           ┆ 0      ┆ No Failure  │\n",
       "│ 9997  ┆ H39410     ┆ H    ┆ 298.9        ┆ … ┆ 31.8        ┆ 17           ┆ 0      ┆ No Failure  │\n",
       "│ 9998  ┆ M24857     ┆ M    ┆ 299.0        ┆ … ┆ 33.4        ┆ 22           ┆ 0      ┆ No Failure  │\n",
       "│ 9999  ┆ H39412     ┆ H    ┆ 299.0        ┆ … ┆ 48.5        ┆ 25           ┆ 0      ┆ No Failure  │\n",
       "│ 10000 ┆ M24859     ┆ M    ┆ 299.0        ┆ … ┆ 40.2        ┆ 30           ┆ 0      ┆ No Failure  │\n",
       "└───────┴────────────┴──────┴──────────────┴───┴─────────────┴──────────────┴────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_csv(\"predictive_maintenance.csv\")\n",
    "features = ['Type',\n",
    " 'Air temperature [K]',\n",
    " 'Process temperature [K]',\n",
    " 'Rotational speed [rpm]',\n",
    " 'Torque [Nm]',\n",
    " 'Tool wear [min]',\n",
    " 'Target',\n",
    " 'Failure Type']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a462cb6",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "Select the features `features` in the dataset.\n",
    "\n",
    "Transform the strings in the columns `Type` and `Failure Type` by integers (which will represent the classes). One can use the method `unique` of `Series` and the method `replace_strict` of `Expr`.\n",
    "\n",
    "Split the columns of the dataset in 3:\n",
    "1. categorical features;\n",
    "2. numerical features;\n",
    "3. targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16338607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db9cc5a8",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Split the dataset into a train set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df4925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57962543",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Perform naive Bayes on the categorial features and on the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72928db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef7fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7618fe2",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Combine the results and compute the accuracy when taking into account both the numerical features and the categorical features.\n",
    "\n",
    "One can access the results of the preceding naive Bayes computations by looking at the attributes and methods of `CategoricalNB` and `GaussianNB` (`class_prior_`, `predict_log_proba`, etc.).\n",
    "\n",
    "Is the combined result better than the two individual results? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d43bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
